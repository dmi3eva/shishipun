{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## TREE #########\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameters:', {'max_features': 4, 'max_depth': 1})\n",
      "('Best score: ', 0.90090090090090091)\n",
      "\n",
      "########## KNN #########\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameters:', {'knn__n_neighbors': 7})\n",
      "('Best score: ', 0.90090090090090091)\n",
      "\n",
      "########## ELM #########\n",
      "(0.44606003752345214, 'ELM(rbf(0.1))', 98)\n",
      "\n",
      "########## SVM #########\n",
      "('Score: ', 0.18058161350844279)\n",
      "SVM-coefficient:\n",
      "[[ 0.44536923 -0.33381518 -0.01556905  0.19590321  0.12624738  0.06933421\n",
      "  -0.07148316 -0.14921394  0.46417226 -0.46217992  0.22840538 -0.07594648\n",
      "  -0.07276618  0.31606644 -0.09257216  0.06227642 -0.11676871 -0.42863163\n",
      "  -0.02068629  0.24361045 -0.35968769  0.01522314 -0.45583473  0.03461724\n",
      "  -0.08626043  0.42859165  0.42517002  0.14132674 -0.38848569  0.16604493\n",
      "  -0.16530289  0.05615412 -0.12094207  0.31624641  0.04040588 -0.40193796]]\n",
      "\n",
      "########## ANN #########\n",
      "('Score (', 16, 17, 'layers): ', 0.39305816135084426)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import csv\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn_extensions.extreme_learning_machines.elm import GenELMClassifier\n",
    "from sklearn_extensions.extreme_learning_machines.random_layer import RBFRandomLayer, MLPRandomLayer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "##################\n",
    "# PREPARING DATA #\n",
    "##################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_binary_label(name_part, dir_name, user_num, not_user_nums):\n",
    "    portion_max_size = 90000\n",
    "    last_num = 0    \n",
    "    label = np.zeros((portion_max_size))    \n",
    "    data = pd.read_csv(dir_name + str(user_num) + '.csv', header=None)    \n",
    "    dim = data.shape[1]\n",
    "    data_matr = data.as_matrix()\n",
    "    data_ar = np.zeros((portion_max_size, dim))\n",
    "    portions_num = data.shape[0]\n",
    "    last_num = data.shape[0]\n",
    "    for i in range(0, last_num):\n",
    "        label[i] = 1\n",
    "        data_ar[i] = data_matr[i]\n",
    "        \n",
    "    for i in not_user_nums:\n",
    "        data = pd.read_csv(dir_name + str(i) + '.csv', header=None)\n",
    "        data_matr = data.as_matrix()\n",
    "        size = data.shape[0]\n",
    "        for j in range(0, size):\n",
    "            label[last_num] = 0\n",
    "            data_ar[last_num] = data_matr[j]\n",
    "            last_num = last_num + 1\n",
    "        portions_num = portions_num + size\n",
    "    \n",
    "    label.resize(portions_num, 1)\n",
    "    data_ar.resize(portions_num, dim) \n",
    "    with open(\"temp/data_auth_\" + name_part + \".csv\", 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        for i in range(0, portions_num):\n",
    "            writer.writerow(data_ar[i])\n",
    "    \n",
    "    with open(\"temp/label_auth_\" + name_part + \".csv\", 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        for i in range(0, portions_num):\n",
    "            writer.writerow(label[i])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def spoil_data(data, persentage):\n",
    "    size = data.shape[0]\n",
    "    \n",
    "    spoilt_size = int(size * persentage)\n",
    "    inds = np.arange(size)\n",
    "    np.random.shuffle(inds)\n",
    "    for i in range(spoilt_size):\n",
    "        data.values[inds[i]] = 0\n",
    "       \n",
    "    return data\n",
    "\n",
    "directory = \"extracted_features/\"\n",
    "make_binary_label(\"all\", directory, 1, [2, 3, 4, 5, 6]) # choosing the user\n",
    "make_binary_label(\"single\", directory, 1, []) # choosing the user\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_single = pd.read_csv(\"temp/data_auth_single.csv\", header=None)\n",
    "label_single = pd.read_csv(\"temp/label_auth_single.csv\", header=None, usecols=[0])\n",
    "\n",
    "\n",
    "data_all = pd.read_csv(\"temp/data_auth_all.csv\", header=None)\n",
    "label_all = pd.read_csv(\"temp/label_auth_all.csv\", header=None)\n",
    "\n",
    "\n",
    "label_spoilt = spoil_data(label_single, 0.1)\n",
    "\n",
    "data_train, label_train = data_single.values, label_spoilt.values\n",
    "data_test, label_test = data_all.values, label_all.values\n",
    "\n",
    "###############\n",
    "#     TREE    #\n",
    "###############\n",
    " \n",
    "#data_train, data_test, label_train, label_test = train_test_split(data_all.values, label_all.values, test_size=0.3,random_state=17)\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=17)\n",
    "tree.fit(data_train, label_train)\n",
    "tree_pred = tree.predict(data_test)\n",
    "acc_tree = accuracy_score(label_test, tree_pred) \n",
    "print('\\n########## TREE #########')\n",
    "#print('Score: ', acc_tree)\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "#Parameter tuning for tree #\n",
    "############################\n",
    "\n",
    "tree_params = {'max_depth': range(1,11), 'max_features': range(4,9)}\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "\n",
    "X_train2, y_train2 = data_single.values, label_spoilt[0]\n",
    "X_holdout2, y_holdout2 = data_all.values, label_all[0]\n",
    "\n",
    "#X_train2, X_holdout2, y_train2, y_holdout2 = train_test_split(data_all.values, label_all[0], test_size=0.3,\n",
    "#random_state=17)\n",
    "tree_grid.fit(X_train2, y_train2)\n",
    "\n",
    "tr_bst_prm = tree_grid.best_params_ #Лучшее сочетание параметров и соответствующая средняя доля правильных ответов на кросс-валидации:\n",
    "tr_bst_scr = tree_grid.best_score_\n",
    "tr_acc_grd = accuracy_score(y_holdout2, tree_grid.predict(X_holdout2))\n",
    "\n",
    "\n",
    "print ('Best parameters:', tr_bst_prm)\n",
    "print('Best score: ', tr_bst_scr)\n",
    "\n",
    "\n",
    "\n",
    "###############\n",
    "#     KNN     #\n",
    "###############\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(data_train, label_train)\n",
    "knn_pred = knn.predict(data_test)\n",
    "acc_knn = accuracy_score(label_test, knn_pred) \n",
    "\n",
    "print('\\n########## KNN #########')\n",
    "#print('Score: ', acc_knn)\n",
    "\n",
    "\n",
    "############################\n",
    "#Parameter tuning for KNN  #\n",
    "############################\n",
    "\n",
    "knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_jobs=-1))])\n",
    "knn_params = {'knn__n_neighbors': range(1, 10)}\n",
    "\n",
    "X_train3, y_train3 = data_single.values, label_spoilt[0]\n",
    "X_holdout3, y_holdout3 = data_all.values, label_all[0]\n",
    "\n",
    "#X_train3, X_holdout3, y_train3, y_holdout3 = train_test_split(data_all.values, label_all[0], test_size=0.3,\n",
    "#random_state=17)\n",
    "\n",
    "\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_params, cv=5, n_jobs=-1, verbose=True)\n",
    "knn_grid.fit(X_train3, y_train3)\n",
    "\n",
    "knn_bst_prm = knn_grid.best_params_\n",
    "knn_bst_scr = knn_grid.best_score_\n",
    "knn_acc_grd = accuracy_score(y_holdout3, knn_grid.predict(X_holdout3))\n",
    "\n",
    "\n",
    "\n",
    "print ('Best parameters:', knn_bst_prm)\n",
    "print('Best score: ', knn_bst_scr)\n",
    "\n",
    "\n",
    "\n",
    "###############\n",
    "#    ELM      #\n",
    "###############\n",
    "print('\\n########## ELM #########')\n",
    "\n",
    "def make_classifiers(nh):\n",
    "    names = [\"ELM(tanh)\", \"ELM(tanh,LR)\", \"ELM(sinsq)\", \"ELM(tribas)\", \"ELM(hardlim)\", \"ELM(rbf(0.1))\"]\n",
    "    \n",
    "\n",
    "    # pass user defined transfer func\n",
    "    sinsq = (lambda x: np.power(np.sin(x), 2.0))\n",
    "    srhl_sinsq = MLPRandomLayer(n_hidden=nh, activation_func=sinsq)\n",
    "\n",
    "    # use internal transfer funcs\n",
    "    srhl_tanh = MLPRandomLayer(n_hidden=nh, activation_func='tanh')\n",
    "    srhl_tribas = MLPRandomLayer(n_hidden=nh, activation_func='tribas')\n",
    "    srhl_hardlim = MLPRandomLayer(n_hidden=nh, activation_func='hardlim')\n",
    "\n",
    "    # use gaussian RBF\n",
    "    srhl_rbf = RBFRandomLayer(n_hidden=nh*2, rbf_width=0.1, random_state=0)\n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    classifiers = [GenELMClassifier(hidden_layer=srhl_tanh),\n",
    "                   GenELMClassifier(hidden_layer=srhl_tanh, regressor=log_reg),\n",
    "                   GenELMClassifier(hidden_layer=srhl_sinsq),\n",
    "                   GenELMClassifier(hidden_layer=srhl_tribas),\n",
    "                   GenELMClassifier(hidden_layer=srhl_hardlim),\n",
    "                   GenELMClassifier(hidden_layer=srhl_rbf)]\n",
    "\n",
    "    return names, classifiers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_score = 0\n",
    "\n",
    "for nh in range (10, 100):\n",
    "    names, classifiers = make_classifiers(nh)\n",
    "    for elm_name, elm_clf in zip(names, classifiers):\n",
    "            #data_train_elm, data_test_elm, label_train_elm, label_test_elm = train_test_split(data_all.values, label_all.values, test_size=0.3,random_state=17)\n",
    "            data_train_elm, label_train_elm = data_single.values, label_spoilt[0]\n",
    "            data_test_elm, label_test_elm = data_all.values, label_all[0]\n",
    "\n",
    "            elm_clf.fit(data_train_elm, label_train_elm)\n",
    "            elm_score = elm_clf.score(data_test_elm, label_test_elm)\n",
    "            if (elm_score > max_score):\n",
    "                max_score = elm_score\n",
    "                max_nh = nh\n",
    "                max_elm_name = elm_name\n",
    "            #print('Model %s score: %s' % (elm_name, elm_score))\n",
    "print(max_score, max_elm_name, max_nh)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############\n",
    "#    SVM      #\n",
    "###############\n",
    "\n",
    "#data_train_svm, data_test_svm, label_train_svm, label_test_svm = train_test_split(data_all.values, label_all.values, test_size=0.3,\n",
    "#random_state=17)\n",
    "\n",
    "\n",
    "data_train_svm, label_train_svm = data_single.values, label_spoilt[0]\n",
    "data_test_svm, label_test_svm = data_all.values, label_all[0]\n",
    "\n",
    "\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(data_train_svm, label_train_svm)\n",
    "\n",
    "clf_pred = clf.predict(data_test_svm)\n",
    "acc_clf = accuracy_score(label_test_svm, clf_pred) \n",
    "\n",
    "print('\\n########## SVM #########')\n",
    "print('Score: ', acc_clf)\n",
    "print('SVM-coefficient:')\n",
    "print(clf.coef_)\n",
    "\n",
    "\n",
    "###############\n",
    "#    ANN      #\n",
    "###############\n",
    "\n",
    "\n",
    "\n",
    "print('\\n########## ANN #########')\n",
    "#data_train_ann, data_test_ann, label_train_ann, label_test_ann = train_test_split(data_all.values, label_all.values, test_size=0.3,\n",
    "#random_state=17)\n",
    "\n",
    "\n",
    "data_train_ann, label_train_ann = data_single.values, label_spoilt[0]\n",
    "data_test_ann, label_test_ann = data_all.values, label_all[0]\n",
    "\n",
    "\n",
    "max_sc_ann = 0\n",
    "\n",
    "for ls2 in range (10,40):\n",
    "    for ls1 in range(8, 20, 2):\n",
    "        ann_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(ls1, ls2), random_state=1)\n",
    "        ann_clf.fit(data_train_ann, label_train_ann)      \n",
    "        ann_clf_pred = ann_clf.predict(data_test_ann)\n",
    "\n",
    "        acc_ann = accuracy_score(label_test_ann, ann_clf_pred) \n",
    "        if (acc_ann > max_sc_ann):\n",
    "            max_sc_ann = acc_ann\n",
    "            max_ls1 = ls1\n",
    "            max_ls2 = ls2\n",
    "                                \n",
    "print('Score (', max_ls1, max_ls2, 'layers): ', max_sc_ann)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
