{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters_names_file = 'res/parameters_names.txt'\n",
    "test_parameters_label_file = \"res/1/test_answer_labels.txt\"\n",
    "test_parameters_features_file = \"res/1/test_answer_features.txt\"\n",
    "\n",
    "train_parameters_label_file = \"res/1/train_answer_labels.txt\"\n",
    "train_parameters_features_file = \"res/1/train_answer_features.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reading data\n",
    "train_features = pd.read_csv(train_parameters_features_file, header=None)\n",
    "train_labels = pd.read_csv(train_parameters_label_file, header=None)\n",
    "test_features = pd.read_csv(test_parameters_features_file, header=None)\n",
    "test_labels = pd.read_csv(test_parameters_label_file, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries for tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tree with split-function\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_test_split(train_features.values, train_labels.values, test_size=0.1,random_state=17)\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(data_train, label_train)\n",
    "clf_pred = clf.predict(data_test)\n",
    "acc_tree = accuracy_score(label_test, clf_pred) \n",
    "print('\\n########## TREE #########')\n",
    "print('Score: ', acc_tree)\n",
    "\n",
    "print(clf.predict([[2.0, 5.0]]))\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "#Parameter tuning for tree #\n",
    "############################\n",
    "\n",
    "tree_params = {'max_depth': range(2,20), 'max_features': range(1,14)}\n",
    "tree_grid = GridSearchCV(clf, tree_params, cv=10, n_jobs=-1, verbose=True)\n",
    "\n",
    "\n",
    "tree_grid.fit(data_train, label_train)\n",
    "\n",
    "tr_bst_prm = tree_grid.best_params_ \n",
    "tr_bst_scr = tree_grid.best_score_\n",
    "tr_acc_grd = accuracy_score(label_test, tree_grid.predict(data_test))\n",
    "\n",
    "\n",
    "print ('Best parameters:', tr_bst_prm)\n",
    "print('Best score: ', tr_bst_scr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train_features_scaled = preprocessing.scale(train_features)\n",
    "test_features_scaled = preprocessing.scale(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#no execution\n",
    "#Tree with preprocessed data\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_features_scaled, test_features_scaled, train_labels, test_labels\n",
    "clf = DecisionTreeRegressor(max_depth=5, random_state=17)\n",
    "clf.fit(data_train, label_train)\n",
    "clf_pred = clf.predict(data_test)\n",
    "acc_tree = accuracy_score(label_test, clf_pred) \n",
    "print('\\n########## TREE #########')\n",
    "print('Score: ', acc_tree)\n",
    "\n",
    "print(clf.predict([[2.0, 11.0]]))\n",
    "\n",
    "\n",
    "############################\n",
    "#Parameter tuning for tree #\n",
    "############################\n",
    "\n",
    "tree_params = {'max_depth': range(2,20), 'max_features': range(1,14)}\n",
    "tree_grid = GridSearchCV(clf, tree_params, cv=10, n_jobs=-1, verbose=True)\n",
    "\n",
    "\n",
    "tree_grid.fit(data_train, label_train)\n",
    "\n",
    "tr_bst_prm = tree_grid.best_params_ \n",
    "tr_bst_scr = tree_grid.best_score_\n",
    "tr_acc_grd = accuracy_score(label_test, tree_grid.predict(data_test))\n",
    "\n",
    "\n",
    "print ('Best parameters:', tr_bst_prm)\n",
    "print('Best score: ', tr_bst_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## TREE #########\n",
      "Score:  0.833333333333\n",
      "[[ 0.  0.  1.]]\n",
      "Fitting 10 folds for each of 234 candidates, totalling 2340 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Done 1504 tasks      | elapsed:    1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 4, 'max_features': 13}\n",
      "Best score:  0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2340 out of 2340 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "#Tree with our test\n",
    "\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_features.values, test_features.values, train_labels.values, test_labels.values\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=17)\n",
    "clf.fit(data_train, label_train)\n",
    "clf_pred = clf.predict(data_test)\n",
    "acc_tree = accuracy_score(label_test, clf_pred) \n",
    "print('\\n########## TREE #########')\n",
    "print('Score: ', acc_tree)\n",
    "\n",
    "print(clf.predict_proba([[7, 0.5, 0.5, 0.5757575757575758, 0.59375, 1, 0, 2.5, 1, 0, 90931315, -17, 135128817935782, 2]]))\n",
    "\n",
    "\n",
    "############################\n",
    "#Parameter tuning for tree #\n",
    "############################\n",
    "\n",
    "tree_params = {'max_depth': range(2,20), 'max_features': range(1,14)}\n",
    "tree_grid = GridSearchCV(clf, tree_params, cv=10, n_jobs=-1, verbose=True)\n",
    "\n",
    "\n",
    "tree_grid.fit(data_train, label_train)\n",
    "\n",
    "tr_bst_prm = tree_grid.best_params_ \n",
    "tr_bst_scr = tree_grid.best_score_\n",
    "tr_acc_grd = accuracy_score(label_test, tree_grid.predict(data_test))\n",
    "\n",
    "\n",
    "print ('Best parameters:', tr_bst_prm)\n",
    "print('Best score: ', tr_bst_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Parameters_defining_tree.pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"Parameters_defining_tree\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-bdedf14aca4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mknn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0macc_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n########## KNN #########'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "data_train, data_test, label_train, label_test = train_features.values, test_features.values, train_labels.values, test_labels.values\n",
    "label_train = np.ravel(label_train)\n",
    "\n",
    "###############\n",
    "#     KNN     #\n",
    "###############\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(data_train, label_train)\n",
    "knn_pred = knn.predict(data_test)\n",
    "acc_knn = accuracy_score(label_test, knn_pred) \n",
    "\n",
    "print('\\n########## KNN #########')\n",
    "print('Score: ', acc_knn)\n",
    "\n",
    "\n",
    "############################\n",
    "#Parameter tuning for KNN  #\n",
    "############################\n",
    "\n",
    "knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_jobs=-1))])\n",
    "knn_params = {'knn__n_neighbors': range(1, 10)}\n",
    "\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_params, cv=5, n_jobs=-1, verbose=True)\n",
    "knn_grid.fit(data_train, label_train)\n",
    "\n",
    "knn_bst_prm = knn_grid.best_params_\n",
    "knn_bst_scr = knn_grid.best_score_\n",
    "knn_acc_grd = accuracy_score(label_train, knn_grid.predict(data_train))\n",
    "\n",
    "print ('Best parameters:', knn_bst_prm)\n",
    "print('Best score: ', knn_bst_scr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## KNN #########\n",
      "Score:  0.916666666667\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'knn__n_neighbors': 1}\n",
      "Best score:  0.666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  65 out of  65 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#KNN with preprocessing\n",
    "data_train, data_test, label_train, label_test = train_features_scaled, test_features_scaled, train_labels, test_labels\n",
    "label_train = np.ravel(label_train)\n",
    "\n",
    "###############\n",
    "#     KNN     #\n",
    "###############\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(data_train, label_train)\n",
    "knn_pred = knn.predict(data_test)\n",
    "acc_knn = accuracy_score(label_test, knn_pred) \n",
    "\n",
    "print('\\n########## KNN #########')\n",
    "print('Score: ', acc_knn)\n",
    "\n",
    "\n",
    "############################\n",
    "#Parameter tuning for KNN  #\n",
    "############################\n",
    "\n",
    "knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_jobs=-1))])\n",
    "knn_params = {'knn__n_neighbors': range(1, 14)}\n",
    "\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_params, cv=5, n_jobs=-1, verbose=True)\n",
    "knn_grid.fit(data_train, label_train)\n",
    "\n",
    "knn_bst_prm = knn_grid.best_params_\n",
    "knn_bst_scr = knn_grid.best_score_\n",
    "knn_acc_grd = accuracy_score(label_train, knn_grid.predict(data_train))\n",
    "\n",
    "print ('Best parameters:', knn_bst_prm)\n",
    "print('Best score: ', knn_bst_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[877.87523496474296, 877.87523496474296, 876.93466874061846, 876.56088521209949]\n",
      "[8.0, 16.0, 128.0, 81.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-5b3937736167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0macc_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n########## SVM #########'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "data_train, data_test, label_train, label_test = train_features.values, test_features.values, train_labels.values, test_labels.values\n",
    "label_test = np.ravel(label_test)\n",
    "label_test  = list(map(float, label_test))\n",
    "\n",
    "################\n",
    "#     SVM      #\n",
    "################\n",
    "\n",
    "clf = svm.SVR()\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "clf_pred = clf.predict(data_test)\n",
    "clf_pred= list(clf_pred)\n",
    "print(clf_pred)\n",
    "print(label_test)\n",
    "acc_clf = accuracy_score(label_test, clf_pred) \n",
    "\n",
    "print('\\n########## SVM #########')\n",
    "print('Score: ', acc_clf)\n",
    "print('SVM-coefficient:')\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## SVM #########\n",
      "Score:  0.833333333333\n",
      "SVM-coefficient:\n",
      "[[ -8.19678222e-01  -7.93742994e-01  -5.54823203e-01   6.19179019e-01\n",
      "    4.06404027e-01  -2.09385425e-01   3.62511927e-01  -2.53765349e-04\n",
      "   -2.28161004e-01  -1.34068068e-01   1.24766423e-02  -2.89846190e-02\n",
      "   -1.31010850e-01   3.37229842e-01]\n",
      " [ -1.03273119e-01   6.26345931e-01   1.88398644e+00  -4.51677756e-01\n",
      "   -1.00888605e+00   4.88434953e-01  -1.70937378e-01  -1.29962809e-01\n",
      "    9.49237221e-01   1.83945781e-01   4.72914249e-03  -1.27240922e+00\n",
      "   -1.69888705e-01  -7.63005505e-02]\n",
      " [  1.43026774e-01   2.75313465e-01  -1.37700541e+00  -5.91323722e-01\n",
      "    1.16808374e+00  -1.92363437e-01  -1.04907156e-01   1.65733225e-02\n",
      "   -4.08649715e-01   8.12473874e-02   7.32715981e-02   5.99030230e-01\n",
      "    2.62258190e-01  -3.67858470e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#SVM  with preprocessing\n",
    "data_train, data_test, label_train, label_test = train_features_scaled, test_features_scaled, train_labels, test_labels\n",
    "\n",
    "\n",
    "###################################\n",
    "#     SVM  with preprocessing     #\n",
    "###################################\n",
    "\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "clf_pred = clf.predict(data_test)\n",
    "acc_clf = accuracy_score(label_test, clf_pred) \n",
    "\n",
    "print('\\n########## SVM #########')\n",
    "print('Score: ', acc_clf)\n",
    "print('SVM-coefficient:')\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries for ANN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## ANN #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score ( 8 14 layers):  0.666666666667\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, label_train, label_test = train_features, test_features, train_labels, test_labels\n",
    "\n",
    "\n",
    "###############\n",
    "#    ANN      #\n",
    "###############\n",
    "\n",
    "\n",
    "print('\\n########## ANN #########')\n",
    "max_sc_ann = 0\n",
    "\n",
    "for ls2 in range (10,40):\n",
    "    for ls1 in range(8, 20, 2):\n",
    "        ann_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(ls1, ls2), random_state=1)\n",
    "        ann_clf.fit(data_train, label_train)      \n",
    "        ann_clf_pred = ann_clf.predict(data_test)\n",
    "\n",
    "        acc_ann = accuracy_score(label_test, ann_clf_pred) \n",
    "        if (acc_ann > max_sc_ann):\n",
    "            max_sc_ann = acc_ann\n",
    "            max_ls1 = ls1\n",
    "            max_ls2 = ls2\n",
    "                                \n",
    "print('Score (', max_ls1, max_ls2, 'layers): ', max_sc_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "\n",
      "########## ANN #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score ( 10 35 layers):  0\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, label_train, label_test = train_features_scaled, test_features_scaled, train_labels, test_labels\n",
    "\n",
    "data_train = data_train[0:25]\n",
    "label_train = label_train[0:25]\n",
    "print(len(data_train))\n",
    "\n",
    "################################\n",
    "#    ANN with preprocessing    #\n",
    "################################\n",
    "\n",
    "\n",
    "print('\\n########## ANN #########')\n",
    "max_sc_ann = 0\n",
    "\n",
    "for ls2 in range (10,40):\n",
    "    for ls1 in range(8, 20, 2):\n",
    "        ann_clf = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(ls1, ls2), random_state=1)\n",
    "        ann_clf.fit(data_train, label_train)      \n",
    "        ann_clf_pred = ann_clf.predict(data_test)\n",
    "        \"\"\"\n",
    "        c_ann = accuracy_score(label_test, ann_clf_pred) \n",
    "        if (acc_ann > max_sc_ann):\n",
    "            max_sc_ann = acc_ann\n",
    "            max_ls1 = ls1\n",
    "            max_ls2 = ls2\n",
    "        \"\"\"                        \n",
    "print('Score (', max_ls1, max_ls2, 'layers): ', max_sc_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
